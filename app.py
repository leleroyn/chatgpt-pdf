import os

import pdfplumber
import streamlit as st
from dotenv import load_dotenv
from service import KnowledgeService as kb


def main():
    chatgpt_model = "gpt-3.5-turbo"
    faiss_index = "index"

    load_dotenv()

    st.set_page_config(page_title="çŸ¥è¯†åº“")
    st.header("ä¸“å±PDFçŸ¥è¯†åº“ğŸ’¬")
    kb_option_list = ("å½“å‰æ–°ç‰ˆæœ¬", "å†å²ç‰ˆæœ¬")
    kb_option = st.selectbox("æŒ‡å®šçŸ¥è¯†åº“æ¨¡å‹", kb_option_list)

    if kb_option == "å½“å‰æ–°ç‰ˆæœ¬":
        faiss_path = "db/pd"
    else:
        faiss_path = "db/sit"

    tab1, tab2 = st.tabs(["ğŸ¡å›ç­”é—®é¢˜", "ğŸ•æ›´æ–°æ¨¡å‹"])

    # ä¸Šä¼ æ–‡ä»¶
    pdf = tab2.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶", type="pdf", help="ä¸è¦é¢‘ç¹çš„æ›´æ–°çŸ¥è¯†åº“,ä¸è¦ä¸Šä¼ å¤§æ–‡ä»¶.")
    # æå–æ–‡æœ¬
    if pdf is not None:
        with tab2.empty():
            st.write("â³æ­£åœ¨æ›´æ–°æ¨¡å‹...")
            text = ""
            with pdfplumber.open(pdf) as pdf_reader:
                for page in pdf_reader.pages:
                    text += page.extract_text()

            knowledge = kb.KnowledgeService(faiss_path, faiss_index).query(faiss_path, faiss_index)
            knowledge.gen(text, os.getenv("SPLITTER_CHUCK_SIZE"), os.getenv("SPLITTER_CHUCK_OVER_LAP"))

            st.success("âœ”ï¸æ›´æ–°æ¨¡å‹æˆåŠŸ.")

    user_question = st.chat_input("â“æ¥å‘æˆ‘æé—®å§ï¼š")
    if user_question:
        st_emt = st.empty()
        st_emt.write("â³æ­£åœ¨æ€è€ƒ,è¯·ç¨ç­‰...")
        knowledge = kb.KnowledgeService(faiss_path, faiss_index)
        response, source_documents, cb = knowledge.query(chatgpt_model, user_question)
        st_emt.write(response)
        # st.info(source_documents)
        st.info(cb)


if __name__ == '__main__':
    main()
