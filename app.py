import os

import pdfplumber
import streamlit as st
from dotenv import load_dotenv
from langchain.callbacks import get_openai_callback
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from service.KnowledgeService import KnowledgeService


def main():
    chatgpt_model = "gpt-3.5-turbo"
    candidate_number = 4
    faiss_index = "index"

    load_dotenv()

    st.set_page_config(page_title="çŸ¥è¯†åº“")
    st.header("ä¸“å±PDFçŸ¥è¯†åº“ğŸ’¬")
    kb_option_list = ("å½“å‰æ–°ç‰ˆæœ¬", "å†å²ç‰ˆæœ¬")
    kb_option = st.selectbox("æŒ‡å®šçŸ¥è¯†åº“æ¨¡å‹", kb_option_list)

    if kb_option == "å½“å‰æ–°ç‰ˆæœ¬":
        faiss_path = "db/pd"
    else:
        faiss_path = "db/sit"

    if st.checkbox("æ˜¯å¦æ›´æ–°æ¨¡å‹"):
        # ä¸Šä¼ æ–‡ä»¶
        pdf = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶", type="pdf")
        # æå–æ–‡æœ¬
        if pdf is not None:
            text = ""
            with pdfplumber.open(pdf) as pdf_reader:
                for page in pdf_reader.pages:
                    text += page.extract_text()

            knowledge = KnowledgeService(faiss_path, faiss_index)
            knowledge.gen(text, os.getenv("SPLITTER_CHUCK_SIZE"), os.getenv("SPLITTER_CHUCK_OVER_LAP"))

            st.success("æ›´æ–°æ¨¡å‹æˆåŠŸ.")
    else:
        user_question = st.text_input("æ¥å‘æˆ‘æé—®å§ï¼š")
        if user_question:
            knowledge = KnowledgeService(faiss_path, faiss_index)
            response, cb = knowledge.query(chatgpt_model, user_question, candidate_number)
            st.write(response)
            st.warning(cb)


if __name__ == '__main__':
    main()
