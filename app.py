import os

import pdfplumber
import streamlit as st
from dotenv import load_dotenv
from service import KnowledgeService


def main():
    chatgpt_model = "gpt-3.5-turbo"
    candidate_number = 4
    faiss_index = "index"

    load_dotenv()

    st.set_page_config(page_title="çŸ¥è¯†åº“")
    st.header("ä¸“å±PDFçŸ¥è¯†åº“ğŸ’¬")
    kb_option_list = ("å½“å‰æ–°ç‰ˆæœ¬", "å†å²ç‰ˆæœ¬")
    kb_option = st.selectbox("æŒ‡å®šçŸ¥è¯†åº“æ¨¡å‹", kb_option_list)

    if kb_option == "å½“å‰æ–°ç‰ˆæœ¬":
        faiss_path = "db/pd"
    else:
        faiss_path = "db/sit"

    tab1, tab2 = st.tabs(["å›ç­”é—®é¢˜", "æ›´æ–°æ¨¡å‹"])

    # ä¸Šä¼ æ–‡ä»¶
    pdf = tab2.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶", type="pdf")
    # æå–æ–‡æœ¬
    if pdf is not None:
        with tab2.empty():
            st.write("â³æ­£åœ¨æ›´æ–°æ¨¡å‹...")
            text = ""
            with pdfplumber.open(pdf) as pdf_reader:
                for page in pdf_reader.pages:
                    text += page.extract_text()

            knowledge = KnowledgeService(faiss_path, faiss_index)
            knowledge.gen(text, os.getenv("SPLITTER_CHUCK_SIZE"), os.getenv("SPLITTER_CHUCK_OVER_LAP"))

            st.success("âœ”ï¸æ›´æ–°æ¨¡å‹æˆåŠŸ.")

    user_question = st.chat_input("â“æ¥å‘æˆ‘æé—®å§ï¼š")
    if user_question:
        user_question = f"å·²çŸ¥ä¿¡æ¯:{user_question}\nè¯·åŸºäºä¸Šé¢çš„å·²çŸ¥ä¿¡æ¯å‡†ç¡®å›ç­”,å¦‚æœä¸çŸ¥é“,ç›´æ¥å›ç­”â€æ ¹æ®å·²æœ‰ä¿¡æ¯æš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ï¼Œè¯·è”ç³»å®¢æœ.â€œ,è¯·ç”¨ä¸­æ–‡å›ç­”."
        st_emt = st.empty()
        st_emt.write("â³æ­£åœ¨æ€è€ƒ,è¯·ç¨ç­‰...")
        knowledge = KnowledgeService(faiss_path, faiss_index)
        response, cb = knowledge.query(chatgpt_model, user_question, candidate_number)
        st_emt.write(response)
        st.info(cb)


if __name__ == '__main__':
    main()
